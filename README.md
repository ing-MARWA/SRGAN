# Super-Resolution GAN (SRGAN) - Anime Face Dataset
This repository contains the implementation of a Super-Resolution Generative Adversarial Network (SRGAN) designed to enhance the resolution of low-quality images. The specific dataset used in this project is the Anime Face Dataset.

The goal of this SRGAN model is to upsample low-resolution (LR) images to high-resolution (HR) while maintaining the quality and details as much as possible. This approach leverages deep learning, particularly GANs, to create realistic high-resolution images.
## Table of Contents
- [Project Overview](#Project Overview)
- [Architecture](#Architecture)
   - [Generator](#Generator)
   - [Discriminator](#Discriminator)
   - [VGG19](#VGG19)
- [Dependencies](#Dependencies)
- [Dataset](#Dataset)
- [Training](#Training)
- [Results](#Results)
- [How to Use](#HowtoUse)
- [References](#References)
# Project Overview
In this project, we implement a Super-Resolution GAN based on deep learning models, including a generator, discriminator, and a pre-trained VGG19 network for feature extraction. The generator aims to convert low-resolution images into high-resolution ones, while the discriminator's role is to distinguish between real HR images and those generated by the model.

The Anime Face Dataset is utilized to train the model, focusing on enhancing the visual quality of anime faces. The dataset contains clean, cropped, 256x256 pixel images of anime characters.
# Architecture
## Generator
The generator is a convolutional neural network (CNN) based on residual blocks. It takes a low-resolution image as input and upsamples it using sub-pixel convolution layers to generate a high-resolution output. The generator architecture consists of:

- **Convolutional Layers with ReLU Activations**
- **Residual Blocks** 
- **Subpixel Layers (for Upsampling)**
## Discriminator
The discriminator is also a CNN that classifies images as either "real" or "generated." It contains:

- **Convolutional layers with LeakyReLU activations**
- **Batch normalization layers to stabilize training**
- **A residual block to further improve performance**
  
# VGG19
A pre-trained VGG19 model is used to extract feature representations from both the real and generated images. This helps the generator focus not just on pixel-level accuracy but also on producing perceptually realistic images. The VGG19 model is loaded up to the 17th layer for feature extraction.
